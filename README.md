# System Autonomes Fahren (T) â€“ SAFT

Projekt zur Entwicklung eines autonomen Fahrsystems mithilfe des Fahrsimulators der Hochschule Harz.
*(Das â€Tâ€œ steht aktuell noch offen â€“ VorschlÃ¤ge sind willkommen!)*

---

## ProjektÃ¼berblick

Dieses Projekt zielt darauf ab, ein System fÃ¼r **autonomes Fahren im Simulator** zu entwickeln.
Dazu werden Sensordaten (z. B. Kameraaufnahmen und Steuerbefehle) aus dem **Fahrsimulator der Hochschule Harz** verarbeitet und fÃ¼r Trainingszwecke eines neuronalen Netzes aufbereitet.

---

## Tools zur Datenvorverarbeitung

### `create_train_data.py`

* Liest **Videodateien** und die zugehÃ¶rigen **TabData-CSV-Dateien** aus dem Simulator.
* Synchronisiert beide Quellen und erzeugt:

  * Einzelbilder (`frames/`)
  * Labeldatei (`labels_to_frames.csv`)
* Parameter wie `trim_video_start_sec` oder `sample_stride` kÃ¶nnen angepasst werden, um Startzeit und Samplingrate zu steuern.

### `crop_finder.py`

* Hilft beim **Bestimmen des passenden Bildausschnitts (Cropping)** fÃ¼r die Trainingsdaten.
* Die Werte des gefunden Crops kÃ¶nnen ausgeben werden und in `create_train_data.py` verwendet werden
* Praktisch, um irrelevante Teile (z. B. Cockpit oder Himmel) zu entfernen.
![Verwendung von crop_finder.py](Pictures/image.png)

### `test_labels.py`

* Visualisiert **Lenkwinkel**, **Throttle** und **Brake** Ã¼ber dem Originalvideo.
* Nutzt das von `create_train_data.py` erzeugte `.csv`.
* Wichtig:

  * `trim_video_start_sec = 0.0`
  * `sample_stride = 1`
    Damit die Label-Zeiten exakt mit den Videoframes Ã¼bereinstimmen.
![alt text](Pictures/image-1.png)
![alt text](Pictures/image-2.png)
---

## Setup & Nutzung

```bash
# Repository klonen
git clone https://github.com/DerNunja/System-Autonomes-Fahren--T-.git
cd System-Autonomes-Fahren--T-

# Virtuelle Umgebung anlegen
python3 -m venv .venv
source .venv/bin/activate

# AbhÃ¤ngigkeiten installieren (sofern requirements.txt existiert)
pip install -r requirements.txt
```

---

## ğŸ§  Geplante Erweiterungen

* Integration eines neuronalen Fahrmodells (Behavioural Cloning)
* Online-Synchronisierung mit dem Weltmodell
* Segmentierungsnetzwerke (UFLD / SegFormer)
* MQTT-basierte Kommunikation zwischen Sensorik und Entscheidungslogik
* Web-Interface zur Visualisierung

---

## ğŸ’¡ Mitwirken

Ideen, Verbesserungen oder NamensvorschlÃ¤ge fÃ¼r das **â€Tâ€œ** sind ausdrÃ¼cklich willkommen!
Erstelle einfach ein Issue oder Ã¶ffne einen Pull Request.

---
