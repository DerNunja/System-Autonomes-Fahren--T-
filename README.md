# System Autonomes Fahren (T) ‚Äì SAFT

Projekt zur Entwicklung eines autonomen Fahrsystems mithilfe des Fahrsimulators der Hochschule Harz.
*(Das ‚ÄûT‚Äú steht aktuell noch offen ‚Äì Vorschl√§ge sind willkommen!)*

---

## Projekt√ºberblick

Dieses Projekt zielt darauf ab, ein System f√ºr **autonomes Fahren im Simulator** zu entwickeln.
Dazu werden Sensordaten (z. B. Kameraaufnahmen und Steuerbefehle) aus dem **Fahrsimulator der Hochschule Harz** verarbeitet und f√ºr Trainingszwecke eines neuronalen Netzes aufbereitet.

---

## Tools zur Datenvorverarbeitung

### `create_train_data.py`

* Liest **Videodateien** und die zugeh√∂rigen **TabData-CSV-Dateien** aus dem Simulator.
* Synchronisiert beide Quellen und erzeugt:

  * Einzelbilder (`frames/`)
  * Labeldatei (`labels_to_frames.csv`)
* Parameter wie `trim_video_start_sec` oder `sample_stride` k√∂nnen angepasst werden, um Startzeit und Samplingrate zu steuern.

### `crop_finder.py`

* Hilft beim **Bestimmen des passenden Bildausschnitts (Cropping)** f√ºr die Trainingsdaten.
* Die Werte des gefunden Crops k√∂nnen ausgeben werden und in `create_train_data.py` verwendet werden
* Praktisch, um irrelevante Teile (z. B. Cockpit oder Himmel) zu entfernen.
![Verwendung von crop_finder.py](image.png)

### `test_labels.py`

* Visualisiert **Lenkwinkel**, **Throttle** und **Brake** √ºber dem Originalvideo.
* Nutzt das von `create_train_data.py` erzeugte `.csv`.
* Wichtig:

  * `trim_video_start_sec = 0.0`
  * `sample_stride = 1`
    Damit die Label-Zeiten exakt mit den Videoframes √ºbereinstimmen.
![alt text](image-1.png)
![alt text](image-2.png)
---

## Setup & Nutzung

```bash
# Repository klonen
git clone https://github.com/DerNunja/System-Autonomes-Fahren--T-.git
cd System-Autonomes-Fahren--T-

# Virtuelle Umgebung anlegen
python3 -m venv .venv
source .venv/bin/activate

# Abh√§ngigkeiten installieren (sofern requirements.txt existiert)
pip install -r requirements.txt
```

---

## üß† Geplante Erweiterungen

* Integration eines neuronalen Fahrmodells (Behavioural Cloning)
* Online-Synchronisierung mit dem Weltmodell
* Segmentierungsnetzwerke (UFLD / SegFormer)
* MQTT-basierte Kommunikation zwischen Sensorik und Entscheidungslogik
* Web-Interface zur Visualisierung

---

## üí° Mitwirken

Ideen, Verbesserungen oder Namensvorschl√§ge f√ºr das **‚ÄûT‚Äú** sind ausdr√ºcklich willkommen!
Erstelle einfach ein Issue oder √∂ffne einen Pull Request.

---
